<!doctype html>
<html lang="en-US" dir="ltr">
<style>
  body {
    font-family: Arial, sans-serif;
    line-height: 1.6;
    max-width: 800px;
    margin: 0 auto;
    padding: 20px;
  }
  h1, h2 {
    color: #333;
  }
  section {
    margin-bottom: 20px;
  }
</style>
<head>
  <title>Speech-to-Text Alpha Generation Research</title>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="description" content="Research on leveraging speech-to-text models for financial market alpha generation">
</head>
<body>
<header>
    <a href="./index.html">Home</a>
</header>

<h1>Leveraging youtube for financial insights</h1>
<p>I'm currently using yt-dlp, whisper, and 3-small to listen to everything that Martin Shkreli says. The 3-small goes into a sqlite3 database which I use for retrieving before feeding it to an LLM.</p>

<p>Currently, the embedding database is stored locally and everything else is done through runpod.io.</p>
<ul>
    <li>yt-dlp</li>
    <li>whisper</li>
    <li>3-small</li>
    <li>llm cli tool</li>
    <li>runpod.io</li>
</ul>

<h2>Components</h2>
<h3>yt-dlp</h3>
<a href="git@github.com:yt-dlp/yt-dlp.git">Yt-dlp</a> downloads youtube videos by simulating a browser with all relevant cookies, rotating proxies to avoid IP bans and making the exact same API calls that would be used to watch a youtube video online. However, this might not be a stable solution for very long due because they might start requesting a proof-of-origin tag.

<h3>Whisper</h3>

<p>Whisper is an open-source model by OpenAI for speech-to-text. I currently use it to convert the raw audio from the YouTube video to a vtt transcript.</p>

<p>In the future, I may move away from this because it may be simpler to just use an API.</p>

<h3>Runpod</h3>

<p>Runpod.io is currently used for 2 things: downloading the video and running Whisper. I don't think this is a good idea long term, because I want my research to be about making the dataset. I want there to be as little as technical innovation in every other area.</p>

<h3>3-small</h3>
3-small is an embedding model from openAI's official API. This is probably my biggest cost. I should proabably move away from this as quickly as possible. It costs me a relavitvely small amount still though, maybe .01 cents each day.

<h3>llm-cli tool</h3>

command line tool created by simonw. Really good documentation. simple to use.

<h2>Data</h2>
<p>Obviously, I want my main contribution to be the data and whisper model finetuning methods. Perhaps not using a transcript API would be useful after all.</p>
<p></p>
</body>
</html>
